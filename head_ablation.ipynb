{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:36.966233Z",
     "start_time": "2025-05-23T07:29:33.515117Z"
    }
   },
   "outputs": [],
   "source": [
    "from reddy_replication_torch.config import config\n",
    "from reddy_replication_torch.experiment import main, eval_loss_and_accuracy, calculate_induction_strength\n",
    "from reddy_replication_torch.model import Transformer\n",
    "import torch\n",
    "from datasets.reddy.datasets_v2 import generate_input_seqs_TI, get_mus_label_class\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import jax.numpy as jnp\n",
    "from itertools import product\n",
    "from plotting_utils import TI_per_pair_plot\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:36.969411Z",
     "start_time": "2025-05-23T07:29:36.968119Z"
    }
   },
   "outputs": [],
   "source": [
    "config.save_model = True\n",
    "config.model.out_dim = config.data.L\n",
    "config.model.n_heads = 8\n",
    "config.train.niters = 4000*10 + 1\n",
    "config.model.w_init_scale=1\n",
    "\n",
    "config.model.n_blocks=2\n",
    "config.model.softmax_attn = [True] * config.model.n_blocks\n",
    "config.model.include_mlp = [False] * config.model.n_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:36.978813Z",
     "start_time": "2025-05-23T07:29:36.970945Z"
    }
   },
   "outputs": [],
   "source": [
    "# load pytorch model from checkpoint\n",
    "config.model_dir = f'models/icl/model_h{config.model.n_heads}'\n",
    "chosen_checkpoint = 40000\n",
    "model_path = os.path.join(config.model_dir, f'cat_I{config.train.niters}_K1024_N12_L32_D63_a0.0_B1_pB1.0_pC1.0_eps0_lr0.01_drop0.0_custom_lnFalse_wDecay1e-07_adam_i{chosen_checkpoint}.pt')\n",
    "if not os.path.exists(model_path):\n",
    "    print('Model not found. Running experiment to train model.')\n",
    "    main(config)\n",
    "# load model\n",
    "model = Transformer(config=config.model)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:36.982117Z",
     "start_time": "2025-05-23T07:29:36.980426Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:36.985224Z",
     "start_time": "2025-05-23T07:29:36.983893Z"
    }
   },
   "outputs": [],
   "source": [
    "# mp = os.path.join('models/icl/model_h2', 'cat_I40000_K1024_N12_L32_D63_a0.0_B1_pB1.0_pC1.0_eps0_lr0.01_drop0.0_custom_lnFalse_wDecay1e-07_adam_i12000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:37.006410Z",
     "start_time": "2025-05-23T07:29:36.985652Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:37.014065Z",
     "start_time": "2025-05-23T07:29:36.987263Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:37.431938Z",
     "start_time": "2025-05-23T07:29:36.992566Z"
    }
   },
   "outputs": [],
   "source": [
    "# eval data\n",
    "S = config.data.S\n",
    "K = config.data.K  # number of classes\n",
    "L = config.data.L  # number of labels\n",
    "D = config.data.D  # dimension of inputs\n",
    "alpha = config.data.alpha  # zipf exponent\n",
    "eps = config.data.eps  # within-class variance\n",
    "# sequence parameters\n",
    "N = config.seq.N\n",
    "B = config.seq.B\n",
    "pB = config.seq.pB\n",
    "pC = config.seq.pC\n",
    "Nmax = config.seq.Nmax  # this is fixed.\n",
    "no_repeats = config.seq.no_repeats\n",
    "\n",
    "mus_label, mus_class, labels_class = get_mus_label_class(config.data.K, config.data.L, config.data.D, seed=0)\n",
    "\n",
    "\n",
    "test_inputs_TI, test_labels_TI = generate_input_seqs_TI(mus_label, mus_class, labels_class, S, N, Nmax, eps=eps,\n",
    "                                                       B=B, p_B=pB, p_C=pC, no_repeats=no_repeats)\n",
    "test_inputs_TI = torch.from_numpy(np.array(test_inputs_TI)).float()\n",
    "test_labels_TI = torch.from_numpy(np.array(test_labels_TI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:38.475619Z",
     "start_time": "2025-05-23T07:29:37.433599Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights)\n",
    "loss = criterion(y_hat, torch.argmax(test_labels_TI.float(), dim=-1))\n",
    "predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "accuracy = (predicted_labels == torch.argmax(test_labels_TI.float(), dim=-1)).float().mean()\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:38.514040Z",
     "start_time": "2025-05-23T07:29:38.476468Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate induction strength\n",
    "induction_strengths = calculate_induction_strength(config, test_inputs_TI, config.train.niters, out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:38.521979Z",
     "start_time": "2025-05-23T07:29:38.499570Z"
    }
   },
   "outputs": [],
   "source": [
    "induction_strengths_dict = {i: induction_strengths[i] for i in range(config.model.n_heads)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:38.522620Z",
     "start_time": "2025-05-23T07:29:38.502370Z"
    }
   },
   "outputs": [],
   "source": [
    "induction_strengths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:44.730401Z",
     "start_time": "2025-05-23T07:29:38.503760Z"
    }
   },
   "outputs": [],
   "source": [
    "# now with ablation\n",
    "\n",
    "accuracy_ablation = {}\n",
    "\n",
    "for h in range(config.model.n_heads):\n",
    "    if h == 4:\n",
    "        accuracy_ablation[h] = None\n",
    "        continue\n",
    "    head_mask = torch.zeros(config.model.n_heads)\n",
    "    head_mask[4] = 1\n",
    "    head_mask[h] = 1\n",
    "    y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights, head_mask=head_mask)\n",
    "    loss = criterion(y_hat, torch.argmax(test_labels_TI.float(), dim=-1))\n",
    "    predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "    accuracy = (predicted_labels == torch.argmax(test_labels_TI.float(), dim=-1)).float().mean()\n",
    "    accuracy_ablation[h] = accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:44.735579Z",
     "start_time": "2025-05-23T07:29:44.733275Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:44.991856Z",
     "start_time": "2025-05-23T07:29:44.740280Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = sns.color_palette('Set1', n_colors=config.model.n_heads)\n",
    "\n",
    "inds2plot = [v for k, v in induction_strengths_dict.items() if k != 4]\n",
    "accs2plot = [v for k, v in accuracy_ablation.items() if k != 4]\n",
    "scatter = plt.scatter(inds2plot, accs2plot, c=np.arange(1,config.model.n_heads), cmap='Set1')\n",
    "plt.legend([f'head {i}' for i in range(config.model.n_heads)])\n",
    "\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=[f'head {i}' for i in range(1, config.model.n_heads)])\n",
    "\n",
    "plt.xlabel('Induction Strength')\n",
    "plt.ylabel('Accuracy (Ablation)')\n",
    "plt.title('Accuracy after ablating all but head i vs Induction Strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:51.927792Z",
     "start_time": "2025-05-23T07:29:44.991201Z"
    }
   },
   "outputs": [],
   "source": [
    "# now with ablating single heads\n",
    "\n",
    "accuracy_ablation_single = {}\n",
    "\n",
    "for h in range(config.model.n_heads):\n",
    "    head_mask = torch.ones(config.model.n_heads)\n",
    "    head_mask[h] = 0\n",
    "    y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights, head_mask=head_mask)\n",
    "    loss = criterion(y_hat, torch.argmax(test_labels_TI.float(), dim=-1))\n",
    "    predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "    accuracy = (predicted_labels == torch.argmax(test_labels_TI.float(), dim=-1)).float().mean()\n",
    "    accuracy_ablation_single[h] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:52.077939Z",
     "start_time": "2025-05-23T07:29:51.932467Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "inds2plot = [induction_strengths_dict[i] for i in range(config.model.n_heads)]\n",
    "accs2plot = [accuracy_ablation_single[i] for i in range(config.model.n_heads)]\n",
    "scatter = plt.scatter(inds2plot, accs2plot, c=np.arange(config.model.n_heads), cmap='Set1')\n",
    "plt.legend([f'head {i}' for i in range(config.model.n_heads)])\n",
    "\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=[f'head {i}' for i in range(config.model.n_heads)])\n",
    "\n",
    "plt.xlabel('Induction Strength')\n",
    "plt.ylabel('Accuracy (Ablation)')\n",
    "plt.title('Accuracy after ablating  vs Induction Strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Now test the model on all symbolic distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:52.078196Z",
     "start_time": "2025-05-23T07:29:52.069960Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_ablation_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:52.084357Z",
     "start_time": "2025-05-23T07:29:52.083044Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_input_seqs_TI(mus_label, mus_class, labels_class, S, N, Nmax, eps=0.1, B=0, p_B=0, P=None, p_C=0,\n",
    "                        flip_labels=False, output_target_labels=False, no_repeats=False, shuffle=True, query_pos=None):\n",
    "\n",
    "    if query_pos is None:\n",
    "        random_query = True\n",
    "    else:\n",
    "        random_query = False\n",
    "\n",
    "    e_fac = 1 / np.sqrt(1 + eps ** 2)\n",
    "\n",
    "    L = mus_label.shape[0]  # number of labels. we could assign a different \"bigger than\" or \"smaller than\" label for each specific sequence\n",
    "\n",
    "    K = mus_class.shape[0]\n",
    "    D = mus_label.shape[1]\n",
    "\n",
    "    N_items = 7\n",
    "    N_pairwise = (N_items - 1) * 2\n",
    "    seq_len = N_pairwise * 2 + 1\n",
    "\n",
    "    K_c = 128  # number of classes to draw from in the fewshot sequences\n",
    "    mus_class_new = np.random.normal(size=(K_c, D // 2)) / np.sqrt(D)\n",
    "    label_mapping_index = np.random.randint(0, L//2, size=(S, 1))\n",
    "\n",
    "    if K_c < L or K_c % L != 0:\n",
    "        print(\"K > L and K%L == 0 is required\")\n",
    "        return 0\n",
    "\n",
    "    inputs = np.zeros((S, seq_len, 2 * Nmax + 1 + D))\n",
    "\n",
    "    item_choices_c = np.array([np.random.choice(np.arange(K_c), size=N_items, replace=False) for _ in range(S)])\n",
    "\n",
    "    item_1_choices_c = np.concatenate([item_choices_c[:, :-1], item_choices_c[:, 1:]], axis=-1)\n",
    "    item_2_choices_c = np.concatenate([item_choices_c[:, 1:], item_choices_c[:, :-1]], axis=-1)\n",
    "    label_choices_c = np.tile(np.repeat(np.arange(2), N_pairwise//2), (S, 1))\n",
    "\n",
    "    converted_label_choices_c = np.zeros_like(label_choices_c)\n",
    "    converted_label_choices_c = np.where((label_choices_c==1), label_mapping_index, converted_label_choices_c)\n",
    "    converted_label_choices_c = np.where((label_choices_c==0), label_mapping_index + L//2, converted_label_choices_c)\n",
    "\n",
    "    random_ordering = np.array([np.random.permutation(N_pairwise) for _ in range(S)])\n",
    "    item_1_choices_c = item_1_choices_c[np.arange(S)[:, None], random_ordering]\n",
    "    item_2_choices_c = item_2_choices_c[np.arange(S)[:, None], random_ordering]\n",
    "    label_choices_c = converted_label_choices_c[np.arange(S)[:, None], random_ordering]\n",
    "\n",
    "    if random_query:\n",
    "        targets_c_ind = np.random.choice(item_1_choices_c.shape[1], size=(item_1_choices_c.shape[0],))\n",
    "        targets_c_1 = item_1_choices_c[np.arange(item_1_choices_c.shape[0]), targets_c_ind]\n",
    "        targets_c_2 = item_2_choices_c[np.arange(item_1_choices_c.shape[0]), targets_c_ind]\n",
    "    else:\n",
    "        # Fixed query positions\n",
    "        targets_c_1 = item_choices_c[np.arange(item_choices_c.shape[0]), query_pos[0]]\n",
    "        targets_c_2 = item_choices_c[np.arange(item_choices_c.shape[0]), query_pos[1]]\n",
    "\n",
    "        # Find the correct index in the shuffled sequence for this specific pair\n",
    "        targets_c_ind = np.zeros(S, dtype=int)\n",
    "        for s in range(S):\n",
    "            # Find where this exact pair appears in the shuffled sequence\n",
    "            matches = np.where((item_1_choices_c[s] == targets_c_1[s]) &\n",
    "                             (item_2_choices_c[s] == targets_c_2[s]))[0]\n",
    "            if len(matches) > 0:\n",
    "                targets_c_ind[s] = matches[0]\n",
    "            else:\n",
    "                # If exact pair not found, this means we need to create it\n",
    "                # Determine the expected label based on the query order\n",
    "                if query_pos[1] > query_pos[0]:\n",
    "                    expected_label = 0  # forward direction\n",
    "                else:\n",
    "                    expected_label = 1  # reverse direction\n",
    "\n",
    "                # Convert to the actual label index\n",
    "                if expected_label == 1:\n",
    "                    expected_converted_label = label_mapping_index[s, 0]\n",
    "                else:\n",
    "                    expected_converted_label = label_mapping_index[s, 0] + L//2\n",
    "\n",
    "                # Find a position with the correct label\n",
    "                label_matches = np.where(label_choices_c[s] == expected_converted_label)[0]\n",
    "                if len(label_matches) > 0:\n",
    "                    targets_c_ind[s] = label_matches[0]\n",
    "                else:\n",
    "                    # This shouldn't happen if the data is set up correctly\n",
    "                    print(f\"Warning: Could not find appropriate label for query {query_pos}\")\n",
    "                    targets_c_ind[s] = 0\n",
    "\n",
    "    filt_C = np.random.uniform(size=S) > p_C\n",
    "\n",
    "    # Fill in the sequences\n",
    "    inputs[~filt_C, :-1:2, 2 * Nmax + 1:-D//2] = \\\n",
    "    (e_fac * (mus_class_new[item_1_choices_c] + eps * np.random.normal(size=(S, N_pairwise, D//2)) / np.sqrt(D//2)))[~filt_C]\n",
    "    inputs[~filt_C, :-1:2, 2 * Nmax + 1 + D//2:-1] = \\\n",
    "    (e_fac * (mus_class_new[item_2_choices_c] + eps * np.random.normal(size=(S, N_pairwise, D//2)) / np.sqrt(D//2)))[~filt_C]\n",
    "\n",
    "    inputs[~filt_C, 1:-1:2, 2 * Nmax + 1:] = ((mus_label[label_choices_c]))[~filt_C]\n",
    "\n",
    "    inputs[~filt_C, -1, 2 * Nmax + 1:-D//2] = \\\n",
    "    (e_fac * (mus_class_new[targets_c_1] + eps * np.random.normal(size=(S, D//2)) / np.sqrt(D//2)))[~filt_C]\n",
    "    inputs[~filt_C, -1, 2 * Nmax + 1 + D//2:-1] = \\\n",
    "    (e_fac * (mus_class_new[targets_c_2] + eps * np.random.normal(size=(S, D//2)) / np.sqrt(D//2)))[~filt_C]\n",
    "\n",
    "    shifts = np.random.choice((2 * Nmax + 1) - seq_len + 1, size=(S))\n",
    "\n",
    "    labels = np.zeros((S, L), dtype=bool)\n",
    "    target_classes = np.zeros(S, dtype=int)\n",
    "\n",
    "    for s in range(S):\n",
    "        if not filt_C[s]:\n",
    "            labels[s, label_choices_c[s, targets_c_ind[s]]] = True\n",
    "            target_classes[s] = -1\n",
    "        else:\n",
    "            raise NotImplementedError('This should not happen')\n",
    "\n",
    "        if shifts[s] + seq_len > 2 * Nmax + 1:\n",
    "            print('Warning: sequence too long for buffer')\n",
    "        inputs[s, :, shifts[s]:shifts[s] + seq_len] = np.identity(seq_len)\n",
    "\n",
    "    # test if sequences is correct (only works for eps=0)\n",
    "    if eps == 0:\n",
    "        for s in range(S):\n",
    "            first_seq = inputs[s][:, 2 * Nmax + 1:]\n",
    "            if random_query and not np.all(first_seq[:-1] == first_seq[-1], axis=1).sum() == 1:\n",
    "                print('warning: egeg ')\n",
    "            target_idx = np.all(first_seq[:-1] ==first_seq[-1], axis=1).argmax()\n",
    "            target_label = np.all(first_seq[target_idx+1] == mus_label, axis=1).argmax()\n",
    "            if random_query and not target_label == labels[s].argmax():\n",
    "                raise ValueError('Target label not found')\n",
    "\n",
    "    if output_target_labels:\n",
    "        return np.array(inputs), jnp.array(labels), target_classes\n",
    "    else:\n",
    "        return jnp.array(inputs), jnp.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:52.086533Z",
     "start_time": "2025-05-23T07:29:52.084537Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_to_uncertainty(accuracy):\n",
    "    # Transform accuracy from [0, 1] to [-1, 1] where 0.5 â†’ 0\n",
    "    return 2 * (accuracy - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.509874Z",
     "start_time": "2025-05-23T07:29:52.089680Z"
    }
   },
   "outputs": [],
   "source": [
    "ranks = np.arange(0, 7)\n",
    "acc_mat = np.zeros((len(ranks), len(ranks)))\n",
    "pred_mat = np.zeros((len(ranks), len(ranks)))\n",
    "pred_for_target_mat = np.zeros((len(ranks), len(ranks)))\n",
    "hiddens = []\n",
    "for i, j in product(ranks, ranks):\n",
    "    if i == j:\n",
    "        continue\n",
    "    test_inputs_TI, test_labels_TI = generate_input_seqs_TI(mus_label, mus_class, labels_class, 1000, N, Nmax, eps=eps,\n",
    "                                                           B=B, p_B=pB, p_C=pC, no_repeats=no_repeats, query_pos=(i, j))\n",
    "\n",
    "    test_inputs_TI = torch.from_numpy(np.array(test_inputs_TI)).float()\n",
    "    test_labels_TI = torch.from_numpy(np.array(test_labels_TI))\n",
    "\n",
    "    y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights, save_hiddens=True)\n",
    "    hiddens.append(out_dict['hidden_activations_1'])\n",
    "    # loss = criterion(y_hat, torch.argmax(test_labels_TI.float(), dim=-1))\n",
    "    predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "    accuracy = (predicted_labels == torch.argmax(test_labels_TI.float(), dim=-1)).float().mean()\n",
    "\n",
    "    true_labels = torch.argmax(test_labels_TI.float(), dim=-1)\n",
    "    # y_hat = torch.softmax(y_hat, dim=-1)\n",
    "\n",
    "    acc_mat[i, j] = accuracy\n",
    "    pred_mat[i, j] = y_hat.mean(axis=0)[0]\n",
    "    pred_for_target_mat[i, j] = accuracy_to_uncertainty(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.516679Z",
     "start_time": "2025-05-23T07:29:57.510286Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.517188Z",
     "start_time": "2025-05-23T07:29:57.511847Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_for_target_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.649222Z",
     "start_time": "2025-05-23T07:29:57.515883Z"
    }
   },
   "outputs": [],
   "source": [
    "test_inputs_TI, test_labels_TI = generate_input_seqs_TI(mus_label, mus_class, labels_class, 1000, N, Nmax, eps=eps,\n",
    "                                                       B=B, p_B=pB, p_C=pC, no_repeats=no_repeats, query_pos=(2, 4))\n",
    "\n",
    "test_inputs_TI = torch.from_numpy(np.array(test_inputs_TI)).float()\n",
    "test_labels_TI = torch.from_numpy(np.array(test_labels_TI))\n",
    "\n",
    "y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights, save_hiddens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.649393Z",
     "start_time": "2025-05-23T07:29:57.641999Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.649760Z",
     "start_time": "2025-05-23T07:29:57.644616Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels_TI[6].float().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.651794Z",
     "start_time": "2025-05-23T07:29:57.647900Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.argmax(test_labels_TI.float(), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.733206Z",
     "start_time": "2025-05-23T07:29:57.652337Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "plt.plot(y_hat[6].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.842716Z",
     "start_time": "2025-05-23T07:29:57.735580Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred_for_target_mat);plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.850105Z",
     "start_time": "2025-05-23T07:29:57.843077Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.850351Z",
     "start_time": "2025-05-23T07:29:57.846040Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:57.933009Z",
     "start_time": "2025-05-23T07:29:57.849071Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(out_dict['block_0']['weights'].mean(axis=0)[4].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.102432Z",
     "start_time": "2025-05-23T07:29:57.945625Z"
    }
   },
   "outputs": [],
   "source": [
    "TI_per_pair_plot(pred_for_target_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.105341Z",
     "start_time": "2025-05-23T07:29:58.103206Z"
    }
   },
   "outputs": [],
   "source": [
    "len(hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.107690Z",
     "start_time": "2025-05-23T07:29:58.106482Z"
    }
   },
   "outputs": [],
   "source": [
    "item_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G']  # Replace with your actual ranks\n",
    "\n",
    "# Generate the labels for off-diagonal elements\n",
    "labels = []\n",
    "symb_distance = []\n",
    "for i, j in product(ranks, ranks):\n",
    "    if i == j:\n",
    "        continue\n",
    "\n",
    "    label = item_labels[i] + item_labels[j]  # Concatenate to form labels like 'AB', 'AC', etc.\n",
    "    labels.append(label)\n",
    "    symb_distance.append(i-j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.267319Z",
     "start_time": "2025-05-23T07:29:58.109318Z"
    }
   },
   "outputs": [],
   "source": [
    "final_token_activations = [h.mean(axis=0)[-1] for h in hiddens]\n",
    "\n",
    "final_token_activations = np.array([np.array(h) for h in final_token_activations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.344155Z",
     "start_time": "2025-05-23T07:29:58.268924Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "X_pca = pca.fit_transform(final_token_activations)  # Shape: [P, 2]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=symb_distance, cmap='coolwarm', s=100)\n",
    "\n",
    "# Add labels for each point\n",
    "for i, inp in enumerate(labels):\n",
    "    plt.annotate(inp, (X_pca[i, 0], X_pca[i, 1]))\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA of final layer Query Token Representations')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.528206Z",
     "start_time": "2025-05-23T07:29:58.348115Z"
    }
   },
   "outputs": [],
   "source": [
    "# make full subplots\n",
    "from definitions import ROOT_FOLDER\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join(ROOT_FOLDER, 'forpaper')\n",
    "df = pd.read_csv(os.path.join(data_dir, 'train_loss.csv'))\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "prefix = 'cat_I40001_K1024_N12_L32_D63_a0.0_B1_pB1.0_pC1.0_eps0_lr0.01_drop0.0_custom_lnFalse_wDecay1e-07_adam - '\n",
    "\n",
    "# Create a mapping for renaming columns\n",
    "rename_dict = {}\n",
    "for col in df.columns:\n",
    "    if col != 'iter' and col.startswith(prefix):\n",
    "        rename_dict[col] = col.replace(prefix, '')\n",
    "\n",
    "# Apply the renaming\n",
    "loss_df = df.rename(columns=rename_dict)\n",
    "\n",
    "loss_df.plot(x='iter', y='train_loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:58.627907Z",
     "start_time": "2025-05-23T07:29:58.529431Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_dir, 'ti_accuracy.csv'))\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "prefix = 'cat_I40001_K1024_N12_L32_D63_a0.0_B1_pB1.0_pC1.0_eps0_lr0.01_drop0.0_custom_lnFalse_wDecay1e-07_adam - '\n",
    "\n",
    "# Create a mapping for renaming columns\n",
    "rename_dict = {}\n",
    "for col in df.columns:\n",
    "    if col != 'iter' and col.startswith(prefix):\n",
    "        rename_dict[col] = col.replace(prefix, '')\n",
    "\n",
    "# Apply the renaming\n",
    "acc_df = df.rename(columns=rename_dict)\n",
    "acc_df.plot(x='iter', y='ti_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:59.766188Z",
     "start_time": "2025-05-23T07:29:58.635963Z"
    }
   },
   "outputs": [],
   "source": [
    "# sns.set_context(\"paper\", font_scale=2.1)\n",
    "sns.set_context(\"paper\", font_scale=3, rc={\"lines.linewidth\": 3})\n",
    "\n",
    "iters = loss_df['iter'].values\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].plot(iters, loss_df['train_loss'])\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].set_xlabel('Training steps')\n",
    "\n",
    "\n",
    "TI_per_pair_plot(pred_for_target_mat, ax=axs[1])\n",
    "axs[1].tick_params(axis='x', labelsize=14)  # x-axis tick labels\n",
    "axs[1].set_title('Predictions by Symbolic Distance')\n",
    "\n",
    "axs[2].plot(iters, acc_df['ti_accuracy'])\n",
    "axs[2].set_ylabel('Accuracy (training)')\n",
    "axs[2].set_xlabel('Training steps')\n",
    "\n",
    "plt.sca(axs[3])\n",
    "axs[3].scatter(X_pca[:, 0], X_pca[:, 1], c=symb_distance, cmap='coolwarm', s=100)\n",
    "\n",
    "# Add labels for each point\n",
    "for i, inp in enumerate(labels):\n",
    "    plt.annotate(inp, (X_pca[i, 0], X_pca[i, 1]), fontsize=15)\n",
    "\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA of L2 Query Representations')\n",
    "\n",
    "for ax in axs:\n",
    "    if ax is axs[1]:\n",
    "        continue\n",
    "    plt.sca(ax)\n",
    "    plt.grid('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('ic_transinf.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:59.767434Z",
     "start_time": "2025-05-23T07:29:59.766090Z"
    }
   },
   "outputs": [],
   "source": [
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Variance explained by PC1: {explained_variance[0]:.4f} ({explained_variance[0]*100:.2f}%)\")\n",
    "print(f\"Variance explained by PC2: {explained_variance[1]:.4f} ({explained_variance[1]*100:.2f}%)\")\n",
    "print(f\"Total variance explained: {sum(explained_variance):.4f} ({sum(explained_variance)*100:.2f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# plotting the attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:29:59.786284Z",
     "start_time": "2025-05-23T07:29:59.766545Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(ROOT_FOLDER, 'forpaper')\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_dir, 'induction_strength.csv'))\n",
    "\n",
    "# Assuming your dataframe is called df\n",
    "prefix = 'cat_I40001_K1024_N12_L32_D63_a0.0_B1_pB1.0_pC1.0_eps0_lr0.01_drop0.0_custom_lnFalse_wDecay1e-07_adam - '\n",
    "\n",
    "# Create a mapping for renaming columns\n",
    "rename_dict = {}\n",
    "for col in df.columns:\n",
    "    if col != 'iter' and col.startswith(prefix):\n",
    "        rename_dict[col] = col.replace(prefix, '')\n",
    "\n",
    "# Apply the renaming\n",
    "df = df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:30:00.377696Z",
     "start_time": "2025-05-23T07:29:59.794835Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "marker_s = 70\n",
    "\n",
    "sns.set_context(\"paper\", font_scale=1.9, rc={\"lines.linewidth\": 3})\n",
    "colors = sns.color_palette(\"Set1\", n_colors=config.model.n_heads)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5), )\n",
    "\n",
    "axs[0].imshow(out_dict['block_0']['weights'].mean(axis=0)[4].detach().numpy())\n",
    "axs[0].set_title('Attention matrix (L1H4)')\n",
    "axs[0].grid('False')\n",
    "axs[0].set_xlabel('Key')\n",
    "axs[0].set_ylabel('Query')\n",
    "\n",
    "cols = [f'induction_strength_TI_head_{i}' for i in range(config.model.n_heads)]\n",
    "axs[1].set_box_aspect(1)\n",
    "df.plot(x='iter', y=cols, ax=axs[1], legend=False, color=colors)\n",
    "axs[1].set_ylabel('Induction Strength')\n",
    "axs[1].set_title('Induction Strength in L2')\n",
    "axs[1].grid('True')\n",
    "\n",
    "axs[2].set_box_aspect(1)\n",
    "plt.sca(axs[2])\n",
    "inds2plot = [induction_strengths_dict[i] for i in range(config.model.n_heads)]\n",
    "accs2plot = [accuracy_ablation_single[i] for i in range(config.model.n_heads)]\n",
    "scatter = plt.scatter(inds2plot, accs2plot, c=colors, s=marker_s)\n",
    "axs[2].grid('True')\n",
    "axs[2].set_xlim(0.18, 0.8)\n",
    "\n",
    "plt.xlabel('Induction Strength')\n",
    "plt.ylabel('Accuracy (Ablation)')\n",
    "plt.title('Accuracy after ablating')\n",
    "\n",
    "\n",
    "inds2plot = [induction_strengths_dict[i] for i in range(config.model.n_heads) if i != 4]\n",
    "accs2plot = [accuracy_ablation[i] for i in range(config.model.n_heads) if i != 4]\n",
    "axs[3].set_box_aspect(1)\n",
    "axs[3].grid('True')\n",
    "axs[3].set_xlim(0.18, 0.8)\n",
    "plt.sca(axs[3])\n",
    "scatter2 = plt.scatter(inds2plot, accs2plot, c=[c for i, c in enumerate(colors) if i != 4], s=marker_s)\n",
    "\n",
    "\n",
    "plt.xlabel('Induction Strength')\n",
    "plt.ylabel('Accuracy (Ablation)')\n",
    "plt.title('Ablating all but head i')\n",
    "\n",
    "\n",
    "# plt.legend([f'head {i}' for i in range(config.model.n_heads)])\n",
    "\n",
    "# plt.legend(handles=scatter.legend_elements()[0], labels=[f'head {i}' for i in range(1, config.model.n_heads)])\n",
    "\n",
    "plt.xlabel('Induction Strength')\n",
    "plt.ylabel('Accuracy (Ablation)')\n",
    "plt.title('Ablating all but head i and 4')\n",
    "legend_labels = [str(i) for i in range(config.model.n_heads)]\n",
    "legend_elements = [plt.Line2D([0], [0], marker='o', color='w', label=label,\n",
    "                              markerfacecolor=color, markersize=8)\n",
    "                   for label, color in zip(legend_labels, colors)]\n",
    "\n",
    "# Add legend to the right of the rightmost plot\n",
    "legend = fig.legend(handles=legend_elements,\n",
    "                    title='L2 head',\n",
    "                    loc='center left',\n",
    "                    bbox_to_anchor=(1.02, 0.5),  # Position to the right\n",
    "                    frameon=True,\n",
    "                    fontsize='small',  # Smaller font\n",
    "                    title_fontsize='medium',\n",
    "                    ncol=1)  # Single column\n",
    "\n",
    "plt.tight_layout()\n",
    "# Make room for the legend on the right\n",
    "plt.subplots_adjust(right=0.9999)\n",
    "\n",
    "for n, ax in enumerate(axs):\n",
    "    ax.text(-0.3, 1.1, string.ascii_uppercase[n], transform=ax.transAxes,\n",
    "            size=20)\n",
    "\n",
    "\n",
    "plt.savefig('IC_attention_weights.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:30:00.380215Z",
     "start_time": "2025-05-23T07:30:00.377304Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_ablation_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:30:00.383595Z",
     "start_time": "2025-05-23T07:30:00.380955Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:30:00.386950Z",
     "start_time": "2025-05-23T07:30:00.385236Z"
    }
   },
   "outputs": [],
   "source": [
    "[c for i, c in enumerate(colors) if i != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:30:00.388602Z",
     "start_time": "2025-05-23T07:30:00.387703Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:13:07.906448Z",
     "start_time": "2025-05-23T09:12:43.193918Z"
    }
   },
   "outputs": [],
   "source": [
    "# do this 10 times\n",
    "\n",
    "pred_mats = []\n",
    "n_runs = 4\n",
    "\n",
    "for run in range(n_runs):\n",
    "    np.random.seed(run)\n",
    "    ranks = np.arange(0, 7)\n",
    "    acc_mat = np.zeros((len(ranks), len(ranks)))\n",
    "    pred_mat = np.zeros((len(ranks), len(ranks)))\n",
    "    pred_for_target_mat = np.zeros((len(ranks), len(ranks)))\n",
    "    hiddens = []\n",
    "    for i, j in product(ranks, ranks):\n",
    "        if i == j:\n",
    "            continue\n",
    "        test_inputs_TI, test_labels_TI = generate_input_seqs_TI(mus_label, mus_class, labels_class, 1000, N, Nmax, eps=eps,\n",
    "                                                               B=B, p_B=pB, p_C=pC, no_repeats=no_repeats, query_pos=(i, j))\n",
    "\n",
    "        test_inputs_TI = torch.from_numpy(np.array(test_inputs_TI)).float()\n",
    "        test_labels_TI = torch.from_numpy(np.array(test_labels_TI))\n",
    "\n",
    "        y_hat, out_dict = model(test_inputs_TI, save_weights=config.save_weights, save_hiddens=True)\n",
    "        hiddens.append(out_dict['hidden_activations_1'])\n",
    "        # loss = criterion(y_hat, torch.argmax(test_labels_TI.float(), dim=-1))\n",
    "        predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "        accuracy = (predicted_labels == torch.argmax(test_labels_TI.float(), dim=-1)).float().mean()\n",
    "\n",
    "        true_labels = torch.argmax(test_labels_TI.float(), dim=-1)\n",
    "        # y_hat = torch.softmax(y_hat, dim=-1)\n",
    "\n",
    "        acc_mat[i, j] = accuracy\n",
    "        pred_mat[i, j] = y_hat.mean(axis=0)[0]\n",
    "        pred_for_target_mat[i, j] = accuracy_to_uncertainty(accuracy)\n",
    "    pred_mats.append(pred_for_target_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:13:07.918337Z",
     "start_time": "2025-05-23T09:13:07.907681Z"
    }
   },
   "outputs": [],
   "source": [
    "from plotting_utils import TI_per_pair_plot_with_confidence_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T09:15:30.078335Z",
     "start_time": "2025-05-23T09:15:29.885995Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred_mats_10runs_icl.npy', np.array(pred_mats))\n",
    "TI_per_pair_plot_with_confidence_intervals(pred_mats, title='ICL model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T07:40:31.452367Z",
     "start_time": "2025-05-23T07:40:31.441322Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T08:28:45.004732Z",
     "start_time": "2025-05-23T08:28:44.995765Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
